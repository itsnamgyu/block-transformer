name: 240408_poc_vanilla_410

wandb: true
wandb_project: block_transformer
wandb_entity: block-transformer
wandb_run_name: null
output_dir: null

wandb_run_id: null
resume_from_checkpoint: false

pythia_pile_idxmaps_path: /data/pythia/pythia_pile_idxmaps
dataset: pythia_pile
total_batch_size: 256
per_device_train_batch_size: 8
gradient_accumulation_steps: null
batch_size_rampup_steps: null
max_length: 2048

tokenizer: pythia

model: gpt-neo-x
model_name_or_path: EleutherAI/pythia-410m-deduped
attn_implementation: flash_attention_2

use_pretrained_weights: false

freeze: false
learning_rate: 3e-4
adam_beta1: 0.9
adam_beta2: 0.95
weight_decay: 0.1
precision: bf16
num_train_steps: 572000
stop_steps: 572000
num_warmup_steps: 3000
save_steps: 10000
save_total_limit: null
logging_steps: 200
dataloader_num_workers: 8

deepspeed: ds_configs/default_linear_warmup.config
