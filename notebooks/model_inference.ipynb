{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72167493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "CHECKPOINT_ROOT = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e677e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate import load_checkpoint_and_dispatch\n",
    "from transformers.generation.streamers import BaseStreamer\n",
    "\n",
    "from model.block_transformer import BlockTransformer\n",
    "from model.utils import load_block_transformer_from_config, load_vanilla_model_from_config\n",
    "from paths import PROJECT_ROOT\n",
    "from util.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e34ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_path(name):\n",
    "    if \".yaml\" not in name:\n",
    "        name += \".yaml\"\n",
    "    return os.path.join(PROJECT_ROOT, \"conf\", \"trainer\", name)\n",
    "\n",
    "\n",
    "def get_checkpoint_path(name):\n",
    "    root = os.path.join(CHECKPOINT_ROOT, name)\n",
    "    if not os.path.exists(root):\n",
    "        raise ValueError(f\"Checkpoint directory does not exist: {root}\")\n",
    "    pattern = os.path.join(CHECKPOINT_ROOT, name, \"checkpoint-*\")\n",
    "    checkpoint_paths = glob.glob(pattern)\n",
    "    def get_step(checkpoint_path):\n",
    "        bs = os.path.basename(checkpoint_path)\n",
    "        return int(bs.split(\"-\")[1])\n",
    "    checkpoint_paths = [(get_step(cp), cp) for cp in checkpoint_paths]\n",
    "    checkpoint_paths.sort()\n",
    "    checkpoint_path = checkpoint_paths[-1][1]\n",
    "    checkpoint_path = os.path.join(checkpoint_path, \"model.safetensors\")\n",
    "    print(f\"Retrieving latest checkpoint path {checkpoint_path}\")\n",
    "    return checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name, block=True)\n",
    "    config = load_config(get_config_path(name))\n",
    "    with init_empty_weights():\n",
    "        if block:\n",
    "            model, tokenizer = load_block_transformer_from_config(config)\n",
    "        else:\n",
    "            model = load_vanilla_model_from_config(config)\n",
    "    checkpoint = get_checkpoint_path(name)\n",
    "    device_map = \"sequential\"  # set to auto to use multiple GPUs + pipelining (not tested)\n",
    "    model = load_checkpoint_and_dispatch(model, checkpoint=checkpoint, device_map=device_map)\n",
    "    if block:\n",
    "        return model, tokenizer\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b56b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_temperature(model, temperature):\n",
    "    if isinstance(model, BlockTransformer):\n",
    "        model.token_decoder.generation_config.update(do_sample=True, temperature=temperature)\n",
    "    else:\n",
    "        model.generation_config.update(do_sample=True, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e031ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstSampleStreamer(BaseStreamer):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.first = True\n",
    "        \n",
    "    def put(self, value):\n",
    "        # ignore prompt\n",
    "        if self.first:\n",
    "            self.first = False\n",
    "            return\n",
    "        token = tokenizer.decode(value[-1]).replace(\"\\n\", \"\\\\n\")\n",
    "        print(token, end=\"\", flush=True)\n",
    "    \n",
    "    def end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489b75d",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4c1357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itsnamgyu/block-transformer/util/config.py:78: UserWarning: stop_steps (572000) is not divisible by save_steps (10000)\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Preprocess Config -------------------------------\n",
      "Automatically determining batch size based on `total_batch_size`\n",
      "total_batch_size              : 256 (given)\n",
      "torch.cuda.device_count()     : 1\n",
      "per_device_train_batch_size   : 8 (given)\n",
      "gradient_accumulation_steps   : 32 (computed)\n",
      "actual total batch size       : 256\n",
      "Setting wandb_run_name    : vanilla_410\n",
      "Setting output_dir        : vanilla_410\n",
      "Using deepspeed config    : /home/itsnamgyu/block-transformer/ds_configs/default_linear_warmup.config\n",
      "--------------------------------------------------------------------------------\n",
      "Initializing model from scratch...\n",
      "Retrieving latest checkpoint path /home/itsnamgyu/x/itsnamgyu/block_transformer_lg/checkpoints/vanilla_410/checkpoint-570000/model.safetensors\n",
      "------------------------------ Preprocess Config -------------------------------\n",
      "Automatically determining batch size based on `total_batch_size`\n",
      "total_batch_size              : 512 (given)\n",
      "torch.cuda.device_count()     : 1\n",
      "per_device_train_batch_size   : 16 (given)\n",
      "gradient_accumulation_steps   : 32 (computed)\n",
      "actual total batch size       : 512\n",
      "Setting wandb_run_name    : block_main_b4_1.2b\n",
      "Setting output_dir        : block_main_b4_1.2b\n",
      "Using deepspeed config    : /home/itsnamgyu/block-transformer/ds_configs/default_linear_warmup.config\n",
      "[token_decoder] Setting num_attention_heads to hidden_size // 128\n",
      "[token_decoder] Setting intermediate_size to hidden_size * 4\n",
      "[block_decoder] Setting num_attention_heads to hidden_size // 128\n",
      "[block_decoder] Setting intermediate_size to hidden_size * 4\n",
      "--------------------------------------------------------------------------------\n",
      "Initializing block decoder from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itsnamgyu/block-transformer/util/config.py:78: UserWarning: stop_steps (286000) is not divisible by save_steps (5000)\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom config for block decoder...\n",
      "   num_hidden_layers: 12\n",
      "   hidden_size: 2048\n",
      "   num_attention_heads: 16\n",
      "   intermediate_size: 8192\n",
      "Initializing embedder from scratch...\n",
      "Using custom config for embedder...\n",
      "   vocab_size: 50304\n",
      "   hidden_size: 512\n",
      "Initializing token decoder from scratch...\n",
      "Using custom config for token decoder...\n",
      "   num_hidden_layers: 12\n",
      "   hidden_size: 2048\n",
      "   num_attention_heads: 16\n",
      "   intermediate_size: 8192\n",
      "Retrieving latest checkpoint path /home/itsnamgyu/x/itsnamgyu/block_transformer_lg/checkpoints/block_main_b4_1.2b/checkpoint-285000/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "vanilla = load_model(\"vanilla_410\", block=False)\n",
    "block, tokenizer = load_model(\"block_main_b4_1.2b\", block=True)\n",
    "# modify if vanilla tokenizer != block embedder tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850739e2",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb4c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"RMS Titanic was a British ocean liner that sank on 15 April 1912 as a result of striking an iceberg on her maiden voyage from Southampton, England to New York City, United States. Of the estimated 2,224 passengers and crew aboard, 1,496 died, making the incident one of the deadliest peacetime sinkings of a single ship.[4] Titanic, operated by the White Star Line, carried some of the wealthiest people in the world, as well as hundreds of emigrants from the British Isles, Scandinavia, and elsewhere in Europe who were seeking a new life in the United States and Canada. The disaster drew public attention, spurred major changes in maritime safety regulations, and inspired a lasting legacy in popular culture.\n",
    "\n",
    "RMS Titanic was the largest ship afloat upon entering service and the second of three Olympic-class ocean liners built for the White Star Line. The ship was built by the Harland and Wolff shipbuilding company in Belfast. Thomas Andrews Jr., the chief naval architect of the shipyard, died in the disaster. Titanic was under the command of Captain Edward John Smith, who went down with the ship.\n",
    "\n",
    "The first-class accommodation was designed to be the pinnacle of comfort and luxury. It included a gymnasium, swimming pool, smoking rooms, fine restaurants and cafes, a Victorian-style Turkish bath, and hundreds of opulent cabins. A high-powered radiotelegraph transmitter was available to send passenger \"marconigrams\" and for the ship's operational use. Titanic had advanced safety features, such as watertight compartments and remotely activated watertight doors, which contributed to the ship's reputation as \"unsinkable\".\n",
    "\n",
    "Titanic was equipped with 16 lifeboat davits, each capable of lowering three lifeboats, for a total capacity of 48 boats. Despite this capacity, the ship was scantly equipped with a total of only 20 lifeboats. Fourteen of these were regular lifeboats, two were cutter lifeboats, and four were collapsible and proved difficult to launch while the ship was sinking. Together, the 20 lifeboats could hold 1,178 people â€” roughly half the number of passengers on board, and a third of the number the passengers the ship could have carried at full capacity (a number consistent with the maritime safety regulations of the era). The British Board of Trade's regulations required 14 lifeboats for a ship 10,000 tonnes. Titanic carried six more than required, allowing 338 extra people room in lifeboats. When the ship sank, the lifeboats that had been lowered were only filled up to an average of 60%.\n",
    "\n",
    "## History\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "632b691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 549\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "prompt_length = len(tokenizer(prompt)[\"input_ids\"])\n",
    "print(\"Prompt length:\", prompt_length)\n",
    "print(\"Batch size:\", batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bfaa73",
   "metadata": {},
   "source": [
    "## Block Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a475020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- Start of generation ------------------------------\n",
      "\\nTitanic was built to be a passenger liner, and that vision soon became reality. By March 1912, the ship was ready to sail. Two weeks later, in May, a severe gash on the stern caused her to crash and sink. She had to be towed to the repair yard's yard, and was not repaired during this time.\\n\\nThree days later, just a day short of the scheduled arrival of a crew, the Titanic went missing again. The ship was unable to resume her normal voyage. After three days of repairs, the ship was finally able to leave Boston, Massachusetts, on May 4. The trip was so slow that the Titanic had barely left dock when she began to list severely, and the passengers had to bathe on the ship. The captain of the Titanic became convinced that the ship would no longer be seaworthy. However, even before it was found-that her original repairs were inadequate-a rescue mission was launched. As Titanic approached, several of the crew jumped to the lifeboat at the front of the ship and were pulled back by the ship's crew. The crew members had their hands tied, and many of them fell overboard. Others were thrown overboard. Many of the passengers were suffocated and died in the water. One passenger, John Francis Doyle, was pulled onto the lifeboat and was drowned. Two more crewmembers died while trying to save others-including Thomas Mouett and William P. Young, the first two to escape from the ship without being put overboard. The captain of the Titanic did not allow any of his crewmembers to take any steps to escape the ship until the ship sank.\\n\\nThe boat sank into the sea because of an unusual combination of bad luck and poor judgment. Despite her size and the fact that her crew was ill-equipped, Titanic would die slowly and painfully throughout her trip. The ship was overloaded, and her watertight hull allowed a small amount of water to get into the engines, and one small, faulty valve kept the ship's main engine from responding quickly enough to prevent the flooding from becoming a serious problem.\\n\\nAfter the ship left Boston on May 8, 1912, passengers were quickly able to buy tickets. When the ship docked in New York, its crew gave the\n",
      "------------------------------ End of generation -------------------------------\n",
      "Prompt tokens per sample     :      549\n",
      "Generated tokens per sample  :      472\n",
      "Batch size                   :       32\n",
      "--------------------------------------------------------------------------------\n",
      "Tok/sec/sample               :    76.19\n",
      "Tok/sec                      :  2438.18\n"
     ]
    }
   ],
   "source": [
    "set_temperature(block, temperature=1)\n",
    "prompts = [prompt] * batch_size\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\")\n",
    "inputs = {k: t.cuda() for k, t in inputs.items()}\n",
    "print(\" Start of generation \".center(80, \"-\"))\n",
    "start = time.time()\n",
    "output_ids = block.generate(**inputs, max_length=1024, print_first_sample=True, tokenizer=tokenizer)\n",
    "\n",
    "duration = time.time() - start\n",
    "n = output_ids.shape[-1]\n",
    "g = n - prompt_length\n",
    "print()\n",
    "print(\" End of generation \".center(80, \"-\"))\n",
    "print(f\"Prompt tokens per sample     : {prompt_length:>8}\")\n",
    "print(f\"Generated tokens per sample  : {g:>8}\")\n",
    "print(f\"Batch size                   : {batch_size:>8}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Tok/sec/sample               : {g/duration:>8.2f}\")\n",
    "print(f\"Tok/sec                      : {g*batch_size/duration:>8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be357ba3",
   "metadata": {},
   "source": [
    "## Vanilla Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c1da58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- Start of generation ------------------------------\n",
      "\\nRMS Titanic was a passenger ship that sank on 14 April 1912 on her maiden voyage from Southampton, England to New York City, United States. The Titanic collides with the Titania ship Chirichestan on 20 May 1912. The ship was an 85-year-old English manufacturer's wooden freighter named the Titanic, or Titanic.\\n\\n## The Ship\\n\\nThe ship was registered in the United States with the U.S. Maritime Administration as U.S. Nautical Sinking Fund Number C-23. According to this chartered service to take passengers to the United States from Southampton (Scotland), England, Canada, and Australia, and from New York (New York) in both a double-decker motor-taxi and a passenger passenger carriage.\\n\\nThis chartered service was a registered charter with a company registered in the United States and the U.S. National Shipbuilding Corporation. The ship was built in Belfast, Ireland by the Harland and Wolff shipbuilding company under the direction of Thomas Andrews Jr. with engineers at the University of Belfast. The ship was launched at Belfast Shipyard on 26 March 1911 and was commissioned on the same day of 22 March by Sir George Alexander. This was the second of the three Olympic-class ships to be built as an Olympic-class liner under the direction of Lord George Gordon. The ship was delivered to the Royal Navy under the command of Captain Roger MacGregor. She joined with the second Olympic-class liner RMS Queen Mary as RMS Olympic, arriving in Southampton on 19 December 1912. The ship left Southampton on 15 April and arrived in New York on 6 May with 827 passengers on board.\\n\\n## Safety\\n\\nSafety on the ship was critical. Titanic had numerous safety features that could have prevented the disaster, but they were insufficient: a watertight watertight compartment, watertight steel doors, a watertight ceiling, smoke masks, a lifeboat davit, emergency lifeboats, lifeboats inflated with inflammable gases, and inflammable gas masks.\\n\\n### Watertight\\n\\nTitanic had a watertight weatherproof compartment; a sealed steel hatch covers; four watertight lifebelts for first-class passengers; and two lifebelts for first-\n",
      "------------------------------ End of generation -------------------------------\n",
      "Prompt tokens per sample     :      549\n",
      "Generated tokens per sample  :      475\n",
      "Batch size                   :       32\n",
      "--------------------------------------------------------------------------------\n",
      "Tok/sec/sample               :    35.29\n",
      "Tok/sec                      :  1129.38\n"
     ]
    }
   ],
   "source": [
    "set_temperature(vanilla, temperature=1)\n",
    "prompts = [prompt] * batch_size\n",
    "streamer = FirstSampleStreamer(tokenizer)\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\")\n",
    "inputs = {k: t.cuda() for k, t in inputs.items()}\n",
    "print(\" Start of generation \".center(80, \"-\"))\n",
    "start = time.time()\n",
    "output_ids = vanilla.generate(**inputs, max_length=1024, streamer=streamer)\n",
    "\n",
    "duration = time.time() - start\n",
    "n = output_ids.shape[-1]\n",
    "g = n - prompt_length\n",
    "print()\n",
    "print(\" End of generation \".center(80, \"-\"))\n",
    "print(f\"Prompt tokens per sample     : {prompt_length:>8}\")\n",
    "print(f\"Generated tokens per sample  : {g:>8}\")\n",
    "print(f\"Batch size                   : {batch_size:>8}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Tok/sec/sample               : {g/duration:>8.2f}\")\n",
    "print(f\"Tok/sec                      : {g*batch_size/duration:>8.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
